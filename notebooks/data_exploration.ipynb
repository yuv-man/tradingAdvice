{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully\n",
      "Will analyze up to 10 stocks\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup environment and load libraries\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables if available\n",
    "try:\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e} - continuing without .env file\")\n",
    "\n",
    "# Create results directory\n",
    "output_dir = os.getenv('OUTPUT_DIR', './results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get configuration from environment or set defaults\n",
    "MAX_SYMBOLS = int(os.getenv('MAX_SYMBOLS', '10'))\n",
    "print(f\"Will analyze up to {MAX_SYMBOLS} stocks\")\n",
    "\n",
    "# Cell 2: Data fetching and preprocessing functions\n",
    "def validate_data_structure(data, symbol):\n",
    "    \"\"\"Validate and clean the data structure\"\"\"\n",
    "    if data is None or len(data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Handle MultiIndex columns from yfinance\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        # Flatten columns by taking the first level\n",
    "        data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing columns {missing_columns} for {symbol}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to numeric and handle any potential issues\n",
    "    for col in required_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "    # Remove rows with any NaN values\n",
    "    initial_rows = len(data)\n",
    "    data = data.dropna()\n",
    "    if len(data) < initial_rows:\n",
    "        print(f\"Removed {initial_rows - len(data)} rows with NaN values for {symbol}\")\n",
    "    \n",
    "    # Check if we still have enough data\n",
    "    if len(data) < 50:\n",
    "        print(f\"Error: Insufficient data for {symbol}. Only {len(data)} rows available.\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_sp500_symbols():\n",
    "    \"\"\"Fetch S&P 500 symbols from Wikipedia\"\"\"\n",
    "    print(\"Fetching S&P 500 symbols...\")\n",
    "    try:\n",
    "        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "        \n",
    "        symbols = []\n",
    "        for row in table.findAll('tr')[1:]:\n",
    "            symbol = row.findAll('td')[0].text.strip()\n",
    "            symbols.append(symbol)\n",
    "        \n",
    "        print(f\"Found {len(symbols)} S&P 500 symbols\")\n",
    "        return symbols\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching S&P 500 symbols: {e}\")\n",
    "        # Return a small fallback list of major companies\n",
    "        return ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "\n",
    "def get_historical_data(symbol, days=360):\n",
    "    \"\"\"Download historical stock data using yfinance\"\"\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    try:\n",
    "        # Download data\n",
    "        data = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        # Validate and clean the data structure\n",
    "        data = validate_data_structure(data, symbol)\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {symbol}: {e}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
